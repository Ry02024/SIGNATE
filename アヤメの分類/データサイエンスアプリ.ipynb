{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPT638lFXJQ3x6hkr3tmTBz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ry02024/SIGNATE/blob/main/%E3%82%A2%E3%83%A4%E3%83%A1%E3%81%AE%E5%88%86%E9%A1%9E/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%82%A2%E3%83%97%E3%83%AA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#streamlit：簡単な分析と機械学習"
      ],
      "metadata": {
        "id": "l9LbUZMA1rxF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##環境構築"
      ],
      "metadata": {
        "id": "d_4FA9X01rxG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit -q\n",
        "!pip install pyngrok -q"
      ],
      "metadata": {
        "id": "-0PRTv841rxG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a2b1872-d8e9-42b5-acb3-14bb3a591d53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m39.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "yXfzNyhE1rxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')"
      ],
      "metadata": {
        "id": "wTBjGPdv1rxG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# ngrokトークンを設定\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0070482-869f-46ae-d6c3-1daee5ecfe1a",
        "id": "SUP7mo2B1rxG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": []
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##実行ファイル"
      ],
      "metadata": {
        "id": "KfkVixYM1rxG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###version1"
      ],
      "metadata": {
        "id": "sMerQbWVeyRE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install japanize-matplotlib -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBdlaDmAAhZs",
        "outputId": "233856e8-b7ef-4049-85b1-0926ee6b7440"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.1/4.1 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for japanize-matplotlib (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###util"
      ],
      "metadata": {
        "id": "mMQqHDnmPaRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile util.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import japanize_matplotlib\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import google.generativeai as genai\n",
        "\n",
        "def load_data(file, drop_id=True):\n",
        "    \"\"\"\n",
        "    ファイルをアップロードし、データフレームを読み込む。\n",
        "    \"\"\"\n",
        "    if file is not None:\n",
        "        data = pd.read_csv(file, delimiter='\\t')\n",
        "        if drop_id and 'id' in data.columns:\n",
        "            data.drop(columns='id', inplace=True)\n",
        "        return data\n",
        "    return None\n",
        "\n",
        "def visualize_data_analysis(data):\n",
        "    \"\"\"\n",
        "    データ分析の可視化を実行する。\n",
        "    \"\"\"\n",
        "    if data is not None:\n",
        "        st.write('基本統計量:')\n",
        "        st.write(data.describe())\n",
        "\n",
        "        st.write('特徴量のヒストグラム:')\n",
        "        fig, ax = plt.subplots()\n",
        "        data.hist(bins=15, figsize=(15, 10), ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        st.write('散布図とカーネル密度推定:')\n",
        "        pair_plot_fig = sns.pairplot(data, hue='class', markers=[\"o\", \"s\", \"D\"], palette=\"bright\")\n",
        "        st.pyplot(pair_plot_fig)\n",
        "\n",
        "        st.write('相関行列:')\n",
        "        numeric_data = data.select_dtypes(include=['number'])\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "def train_and_evaluate_model(train_data, test_data):\n",
        "    \"\"\"\n",
        "    モデルを訓練し、評価指標を表示する。\n",
        "    \"\"\"\n",
        "    if train_data is not None and test_data is not None:\n",
        "        # 特徴量とターゲットに分割\n",
        "        X_train = train_data.drop('class', axis=1)\n",
        "        y_train = train_data['class']\n",
        "        X_test = test_data\n",
        "\n",
        "        # 特徴量のスケーリング\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # モデル構築とハイパーパラメータのチューニング\n",
        "        model = RandomForestClassifier(random_state=42)\n",
        "        param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}\n",
        "        grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "        grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # 最適なモデルを取得\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # 訓練データに対する予測\n",
        "        y_train_pred = best_model.predict(X_train_scaled)\n",
        "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "        train_confusion = confusion_matrix(y_train, y_train_pred)\n",
        "\n",
        "        # 適合率、再現率、F1スコアを計算\n",
        "        precision = precision_score(y_train, y_train_pred, average='macro')\n",
        "        recall = recall_score(y_train, y_train_pred, average='macro')\n",
        "        f1 = f1_score(y_train, y_train_pred, average='macro')\n",
        "\n",
        "        st.write(\"訓練データの精度: \", train_accuracy)\n",
        "        st.write(\"適合率:\", precision)\n",
        "        st.write(\"再現率:\", recall)\n",
        "        st.write(\"F1スコア:\", f1)\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.heatmap(train_confusion, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "        plt.title(\"訓練データの混同行列\")\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # テストデータに対する予測\n",
        "        y_test_pred = best_model.predict(X_test_scaled)\n",
        "        st.write(\"テストデータの予測結果:\")\n",
        "        st.write(pd.DataFrame({'Prediction': y_test_pred}))\n",
        "\n",
        "        # 予測結果の要約を生成\n",
        "        prediction_summary = f\"\"\"\n",
        "        訓練データの精度: {train_accuracy}\n",
        "        適合率: {precision}\n",
        "        再現率: {recall}\n",
        "        F1スコア: {f1}\n",
        "        \"\"\"\n",
        "        return prediction_summary, y_test_pred\n",
        "    return None, None\n",
        "\n",
        "def get_insights_from_gemini(summary, y_test_pred):\n",
        "    \"\"\"\n",
        "    Gemini APIを使用して、予測結果に基づいた知見を取得する。\n",
        "    \"\"\"\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    combined_text = f\"\"\"\n",
        "    以下の予測結果に基づいて、モデルのパフォーマンスと結果についての詳細な分析を提供してください。\n",
        "\n",
        "    **予測結果の要約:**\n",
        "    {summary}\n",
        "\n",
        "    **テストデータの予測結果:**\n",
        "    {y_test_pred}\n",
        "    \"\"\"\n",
        "    response = model.generate_content(combined_text)\n",
        "    return response.text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4w1tFwWPdBa",
        "outputId": "6aa5ae82-0323-469f-d79b-bd3814be3f1f"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting util.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import japanize_matplotlib\n",
        "from util import load_data, visualize_data_analysis, train_and_evaluate_model, get_insights_from_gemini\n",
        "\n",
        "st.title('アヤメの品種分類アプリ')\n",
        "st.write('このアプリはアヤメのデータセットを分析し、品種を予測します。')\n",
        "\n",
        "# APIキー入力部分\n",
        "api_key = st.text_input(\"APIキーを入力してください:\", value=\"\", type=\"password\")\n",
        "\n",
        "if api_key:\n",
        "    import google.generativeai as genai\n",
        "    genai.configure(api_key=api_key)\n",
        "\n",
        "# ファイルアップローダー\n",
        "train_file = st.file_uploader(\"訓練データをアップロードしてください（train.tsv）\", type=['tsv'])\n",
        "test_file = st.file_uploader(\"テストデータをアップロードしてください（test.tsv）\", type=['tsv'])\n",
        "\n",
        "if train_file is not None and test_file is not None:\n",
        "    train_data = load_data(train_file)\n",
        "    test_data = load_data(test_file, drop_id=True)\n",
        "\n",
        "    # データの表示\n",
        "    st.write(\"訓練データの最初の5行:\")\n",
        "    st.write(train_data.head())\n",
        "    st.write(\"テストデータの最初の5行:\")\n",
        "    st.write(test_data.head())\n",
        "\n",
        "    # 基本統計と分布の表示\n",
        "    if st.checkbox('基本統計と分布を表示'):\n",
        "        visualize_data_analysis(train_data)\n",
        "\n",
        "    # 散布図とカーネル密度推定\n",
        "    if st.checkbox('散布図とカーネル密度推定を表示'):\n",
        "        pair_plot_fig = sns.pairplot(train_data, hue='class', markers=[\"o\", \"s\", \"D\"], palette=\"bright\")\n",
        "        st.pyplot(pair_plot_fig)\n",
        "\n",
        "    # 相関行列\n",
        "    if st.checkbox('相関行列を表示'):\n",
        "        numeric_data = train_data.select_dtypes(include=['number'])\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "    # モデルの訓練と評価\n",
        "    if st.button('モデルを訓練して評価'):\n",
        "        summary, y_test_pred = train_and_evaluate_model(train_data, test_data)\n",
        "        if summary:\n",
        "            st.write(\"モデルのパフォーマンス要約:\")\n",
        "            st.write(summary)\n",
        "\n",
        "            # Geminiを使って知見を取得\n",
        "            insights = get_insights_from_gemini(summary, y_test_pred)\n",
        "            st.write(\"Geminiからの知見:\")\n",
        "            st.write(insights)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J2BBC4xxPw5X",
        "outputId": "9603f486-2e31-4e7b-b7c7-8d31b62a4839"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##アプリの起動"
      ],
      "metadata": {
        "id": "W4iAda4i1rxH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ngrokを介してStreamlitを公開\n",
        "public_url = ngrok.connect(addr='8501')\n",
        "print('Public URL:', public_url)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18dd08fd-2f66-4280-cdc5-8af6b6ca7782",
        "id": "17c_nK0C1rxH"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://a4d5-34-136-117-121.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Streamlitアプリケーションの起動\n",
        "!streamlit run streamlit_app.py >/dev/null"
      ],
      "metadata": {
        "id": "RL66sp521rxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8d2fb51-e343-47ef-a2a8-b077a127ad5e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/util.py:33: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared.\n",
            "  data.hist(bins=15, figsize=(15, 10), ax=ax)\n",
            "/content/util.py:33: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared.\n",
            "  data.hist(bins=15, figsize=(15, 10), ax=ax)\n",
            "/content/util.py:33: UserWarning: To output multiple subplots, the figure containing the passed axes is being cleared.\n",
            "  data.hist(bins=15, figsize=(15, 10), ax=ax)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJt2fSkIBx_X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}