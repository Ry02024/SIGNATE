{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNyyjtpXBeLCyfT2BxkKRxt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ry02024/SIGNATE/blob/main/%E6%B1%8E%E5%8C%96/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9%E3%82%A2%E3%83%97%E3%83%AA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#streamlit：汎用化"
      ],
      "metadata": {
        "id": "Y6oQdrQwwpUT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##環境構築"
      ],
      "metadata": {
        "id": "V2rT_d8zwpUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit -q\n",
        "!pip install pyngrok -q"
      ],
      "metadata": {
        "id": "tAg0An_fwpUb"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import streamlit as st\n",
        "from pyngrok import ngrok"
      ],
      "metadata": {
        "id": "z91HMyvHwpUb"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')"
      ],
      "metadata": {
        "id": "0rul09UDwpUb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import os\n",
        "\n",
        "# ngrokトークンを設定\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)"
      ],
      "metadata": {
        "id": "7dE6ZS56wpUb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##実行ファイル"
      ],
      "metadata": {
        "id": "mMLKFCp7wpUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install japanize-matplotlib -q"
      ],
      "metadata": {
        "id": "nOayu1E3wpUc"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###util.py"
      ],
      "metadata": {
        "id": "UwUy-ixgwpUc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile util.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import japanize_matplotlib\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score\n",
        "import google.generativeai as genai\n",
        "import chardet\n",
        "\n",
        "def detect_delimiter(file):\n",
        "    \"\"\"\n",
        "    ファイルのデリミタを自動検出する。\n",
        "    \"\"\"\n",
        "    result = chardet.detect(file.read())\n",
        "    file.seek(0)  # ファイルポインタをリセット\n",
        "    sample = file.read(2048).decode(result['encoding'])\n",
        "    file.seek(0)  # ファイルポインタをリセット\n",
        "    delimiters = [',', '\\t']\n",
        "    for delimiter in delimiters:\n",
        "        if delimiter in sample:\n",
        "            return delimiter\n",
        "    return ','  # デフォルトはカンマ区切り\n",
        "\n",
        "def load_data(file, drop_id=True):\n",
        "    \"\"\"\n",
        "    ファイルをアップロードし、デリミタを自動検出してデータフレームを読み込む。\n",
        "    \"\"\"\n",
        "    if file is not None:\n",
        "        delimiter = detect_delimiter(file)\n",
        "        data = pd.read_csv(file, delimiter=delimiter)\n",
        "        if drop_id and 'id' in data.columns:\n",
        "            data.drop(columns='id', inplace=True)\n",
        "        return data\n",
        "    return None\n",
        "\n",
        "def find_target_column(train_data, test_data):\n",
        "    \"\"\"\n",
        "    訓練データとテストデータの差分から目的変数のカラム名を自動判別する。\n",
        "    \"\"\"\n",
        "    train_columns = set(train_data.columns)\n",
        "    test_columns = set(test_data.columns)\n",
        "    target_columns = list(train_columns - test_columns)\n",
        "    if len(target_columns) == 1:\n",
        "        return target_columns[0]\n",
        "    else:\n",
        "        return None\n",
        "\n",
        "def visualize_data_analysis(data, target_col):\n",
        "    \"\"\"\n",
        "    データ分析の可視化を実行する。\n",
        "    \"\"\"\n",
        "    if data is not None:\n",
        "        st.write('基本統計量:')\n",
        "        st.write(data.describe())\n",
        "\n",
        "        st.write('特徴量のヒストグラム:')\n",
        "        fig, ax = plt.subplots()\n",
        "        data.hist(bins=15, figsize=(15, 10), ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        st.write('散布図とカーネル密度推定:')\n",
        "        pair_plot_fig = sns.pairplot(data, hue=target_col, markers=[\"o\", \"s\", \"D\"], palette=\"bright\")\n",
        "        st.pyplot(pair_plot_fig)\n",
        "\n",
        "        st.write('相関行列:')\n",
        "        numeric_data = data.select_dtypes(include=['number'])\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.heatmap(numeric_data.corr(), annot=True, cmap='coolwarm', ax=ax)\n",
        "        st.pyplot(fig)\n",
        "\n",
        "def summarize_visualizations(data):\n",
        "    \"\"\"\n",
        "    データの可視化結果を要約する。\n",
        "    \"\"\"\n",
        "    summary = \"\"\n",
        "\n",
        "    # 基本統計量\n",
        "    summary += \"基本統計量:\\n\"\n",
        "    summary += data.describe().to_markdown() + \"\\n\\n\"\n",
        "\n",
        "    # ヒストグラム\n",
        "    summary += \"特徴量のヒストグラム:\\n\"\n",
        "    for column in data.columns:\n",
        "        if data[column].dtype in ['int64', 'float64']:\n",
        "            summary += f\"{column}の分布: 平均={data[column].mean()}, 標準偏差={data[column].std()}, 最大値={data[column].max()}, 最小値={data[column].min()}\\n\"\n",
        "\n",
        "    # 相関行列\n",
        "    numeric_data = data.select_dtypes(include=['number'])\n",
        "    corr_matrix = numeric_data.corr()\n",
        "    summary += \"\\n相関行列:\\n\"\n",
        "    summary += corr_matrix.to_markdown() + \"\\n\"\n",
        "\n",
        "    # 散布図\n",
        "    summary += \"\\n散布図:\\n\"\n",
        "    summary += \"各特徴量間の散布図は以下のように分布しています。\\n\"\n",
        "\n",
        "    return summary\n",
        "\n",
        "def generate_insights(data):\n",
        "    if data is not None:\n",
        "        insights = []\n",
        "        desc = data.describe()\n",
        "\n",
        "        # 基本統計量からの知見\n",
        "        insights.append(\"基本統計量から、各特徴量の平均値、中央値、標準偏差がわかります。これにより、特徴量の分布と中心傾向が理解できます。\")\n",
        "\n",
        "        # 相関行列からの知見\n",
        "        numeric_data = data.select_dtypes(include=['number'])\n",
        "        corr_matrix = numeric_data.corr()\n",
        "        high_corr = corr_matrix[(corr_matrix > 0.7) & (corr_matrix != 1.0)]\n",
        "        if not high_corr.empty:\n",
        "            insights.append(\"相関行列から、以下の特徴量間で強い相関が見られます:\")\n",
        "            insights.append(high_corr.dropna(how='all').dropna(axis=1, how='all').to_markdown())\n",
        "        else:\n",
        "            insights.append(\"相関行列から、特徴量間に強い相関は見られませんでした。\")\n",
        "\n",
        "        return insights\n",
        "    return []\n",
        "\n",
        "def train_and_evaluate_model(train_data, test_data, target_col, model_name='RandomForest'):\n",
        "    \"\"\"\n",
        "    モデルを訓練し、評価指標を表示する。\n",
        "    \"\"\"\n",
        "    if train_data is not None and test_data is not None:\n",
        "        # 特徴量とターゲットに分割\n",
        "        X_train = train_data.drop(target_col, axis=1)\n",
        "        y_train = train_data[target_col]\n",
        "        X_test = test_data\n",
        "\n",
        "        # 特徴量のスケーリング\n",
        "        scaler = StandardScaler()\n",
        "        X_train_scaled = scaler.fit_transform(X_train)\n",
        "        X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "        # モデル構築とハイパーパラメータのチューニング\n",
        "        if model_name == 'RandomForest':\n",
        "            model = RandomForestClassifier(random_state=42)\n",
        "            param_grid = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20, 30]}\n",
        "        elif model_name == 'LogisticRegression':\n",
        "            model = LogisticRegression(random_state=42, max_iter=1000)\n",
        "            param_grid = {'C': [0.01, 0.1, 1, 10, 100]}\n",
        "\n",
        "        grid_search = GridSearchCV(model, param_grid, cv=5)\n",
        "        grid_search.fit(X_train_scaled, y_train)\n",
        "\n",
        "        # 最適なモデルを取得\n",
        "        best_model = grid_search.best_estimator_\n",
        "\n",
        "        # 訓練データに対する予測\n",
        "        y_train_pred = best_model.predict(X_train_scaled)\n",
        "        train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "        train_confusion = confusion_matrix(y_train, y_train_pred)\n",
        "\n",
        "        # 適合率、再現率、F1スコアを計算\n",
        "        precision = precision_score(y_train, y_train_pred, average='macro')\n",
        "        recall = recall_score(y_train, y_train_pred, average='macro')\n",
        "        f1 = f1_score(y_train, y_train_pred, average='macro')\n",
        "\n",
        "        st.write(\"訓練データの精度: \", train_accuracy)\n",
        "        st.write(\"適合率:\", precision)\n",
        "        st.write(\"再現率:\", recall)\n",
        "        st.write(\"F1スコア:\", f1)\n",
        "        fig, ax = plt.subplots()\n",
        "        sns.heatmap(train_confusion, annot=True, fmt='d', cmap='Blues', ax=ax)\n",
        "        plt.title(\"訓練データの混同行列\")\n",
        "        st.pyplot(fig)\n",
        "\n",
        "        # テストデータに対する予測\n",
        "        y_test_pred = best_model.predict(X_test_scaled)\n",
        "        st.write(\"テストデータの予測結果:\")\n",
        "        st.write(pd.DataFrame({'Prediction': y_test_pred}))\n",
        "\n",
        "        # 予測結果の要約を生成\n",
        "        prediction_summary = f\"\"\"\n",
        "        訓練データの精度: {train_accuracy}\n",
        "        適合率: {precision}\n",
        "        再現率: {recall}\n",
        "        F1スコア: {f1}\n",
        "        \"\"\"\n",
        "        return prediction_summary, y_test_pred\n",
        "    return None, None\n",
        "\n",
        "def get_visualization_insights(visualization_summary):\n",
        "    \"\"\"\n",
        "    データ分析の可視化結果に基づいた知見を取得する。\n",
        "    \"\"\"\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    combined_text = f\"\"\"\n",
        "    以下のデータ分析結果に基づいて、データの詳細な分析を提供してください。\n",
        "\n",
        "    **データの可視化結果の要約:**\n",
        "    {visualization_summary}\n",
        "    \"\"\"\n",
        "    response = model.generate_content(combined_text)\n",
        "    return response.text\n",
        "\n",
        "def get_insights_from_gemini(summary, y_test_pred):\n",
        "    \"\"\"\n",
        "    Gemini APIを使用して、予測結果に基づいた知見を取得する。\n",
        "    \"\"\"\n",
        "    model = genai.GenerativeModel('gemini-pro')\n",
        "    combined_text = f\"\"\"\n",
        "    以下の予測結果に基づいて、モデルのパフォーマンスと結果についての詳細な分析を提供してください。\n",
        "\n",
        "    **予測結果の要約:**\n",
        "    {summary}\n",
        "\n",
        "    **テストデータの予測結果:**\n",
        "    {y_test_pred}\n",
        "    \"\"\"\n",
        "    response = model.generate_content(combined_text)\n",
        "    return response.text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "050739fc-c770-4e0d-c3ed-dcf82951e036",
        "id": "KUFstFO-wpUc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting util.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###streamlit_app.py"
      ],
      "metadata": {
        "id": "HAL4nyJrwpUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile streamlit_app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import japanize_matplotlib\n",
        "from util import load_data, visualize_data_analysis, train_and_evaluate_model, get_insights_from_gemini, generate_insights, summarize_visualizations, get_visualization_insights, find_target_column\n",
        "\n",
        "# Streamlitの設定\n",
        "st.set_page_config(page_title=\"データ分析と機械学習アプリ\", layout=\"wide\")\n",
        "\n",
        "st.title('データ分析と機械学習アプリ')\n",
        "st.write('このアプリはアップロードされたデータセットを分析し、予測モデルを構築します。')\n",
        "\n",
        "# APIキー入力部分\n",
        "api_key = st.text_input(\"APIキーを入力してください:\", value=\"\", type=\"password\")\n",
        "\n",
        "if api_key:\n",
        "    import google.generativeai as genai\n",
        "    genai.configure(api_key=api_key)\n",
        "\n",
        "# ファイルアップローダー\n",
        "train_file = st.file_uploader(\"訓練データをアップロードしてください（csvまたはtsv形式）\", type=['csv', 'tsv'])\n",
        "test_file = st.file_uploader(\"テストデータをアップロードしてください（csvまたはtsv形式）\", type=['csv', 'tsv'])\n",
        "\n",
        "# モデル選択\n",
        "model_name = st.selectbox(\"使用するモデルを選択してください:\", ['RandomForest', 'LogisticRegression'])\n",
        "\n",
        "# セッションステートを初期化\n",
        "if 'visualization_insights' not in st.session_state:\n",
        "    st.session_state.visualization_insights = None\n",
        "\n",
        "# チャットボットの初期化\n",
        "if 'chat_history' not in st.session_state:\n",
        "    st.session_state.chat_history = []\n",
        "\n",
        "# レイアウト設定\n",
        "col1, col2 = st.columns([3, 1])\n",
        "\n",
        "with col1:\n",
        "    if train_file is not None and test_file is not None:\n",
        "        train_data = load_data(train_file)\n",
        "        test_data = load_data(test_file, drop_id=True)\n",
        "\n",
        "        # ターゲット変数の自動判別\n",
        "        target_col = find_target_column(train_data, test_data)\n",
        "        if target_col is None:\n",
        "            st.error(\"訓練データとテストデータの差分から目的変数を特定できませんでした。\")\n",
        "        else:\n",
        "            st.write(f\"自動検出された目的変数: {target_col}\")\n",
        "\n",
        "            # データの表示\n",
        "            st.write(\"訓練データの最初の5行:\")\n",
        "            st.write(train_data.head())\n",
        "            st.write(\"テストデータの最初の5行:\")\n",
        "            st.write(test_data.head())\n",
        "\n",
        "            # 基本統計と分布の表示\n",
        "            if st.checkbox('可視化によるデータ分析'):\n",
        "                visualize_data_analysis(train_data, target_col)\n",
        "\n",
        "                if st.button('Geminiに可視化結果を分析させる'):\n",
        "                    visualization_summary = summarize_visualizations(train_data)\n",
        "                    st.session_state.visualization_insights = get_visualization_insights(visualization_summary)\n",
        "\n",
        "            # セッションステートに保存されたGeminiからの知見を表示\n",
        "            if st.session_state.visualization_insights:\n",
        "                st.write(\"Geminiからの知見:\")\n",
        "                st.write(st.session_state.visualization_insights)\n",
        "\n",
        "            # モデルの訓練と評価\n",
        "            if st.button('モデルを訓練して評価'):\n",
        "                summary, y_test_pred = train_and_evaluate_model(train_data, test_data, target_col, model_name)\n",
        "                if summary:\n",
        "                    st.write(\"モデルのパフォーマンス要約:\")\n",
        "                    st.write(summary)\n",
        "\n",
        "                    # Geminiを使って知見を取得\n",
        "                    insights = get_insights_from_gemini(summary, y_test_pred)\n",
        "                    st.write(\"Geminiからの知見:\")\n",
        "                    st.write(insights)\n",
        "\n",
        "with col2:\n",
        "    st.sidebar.title(\"Geminiチャットボット\")\n",
        "    query = st.sidebar.text_area(\"質問を入力してください:\", key=\"query\")\n",
        "\n",
        "    if st.sidebar.button(\"送信\"):\n",
        "        if api_key:\n",
        "            model = genai.GenerativeModel('gemini-pro')\n",
        "            response = model.generate_content(query)\n",
        "            st.session_state.chat_history.append({\"query\": query, \"response\": response.text})\n",
        "        else:\n",
        "            st.sidebar.error(\"APIキーを入力してください。\")\n",
        "\n",
        "    # チャット履歴を表示\n",
        "    if st.session_state.chat_history:\n",
        "        for chat in st.session_state.chat_history:\n",
        "            st.sidebar.write(f\"**質問**: {chat['query']}\")\n",
        "            st.sidebar.write(f\"**回答**: {chat['response']}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "80554a90-6919-4b08-8517-72b0a40142eb",
        "id": "jNLW2clJwpUd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting streamlit_app.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##アプリの起動"
      ],
      "metadata": {
        "id": "XR8qIM52wpUd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ngrokを介してStreamlitを公開\n",
        "public_url = ngrok.connect(addr='8501')\n",
        "print('Public URL:', public_url)\n",
        "# Streamlitアプリケーションの起動\n",
        "!streamlit run streamlit_app.py >/dev/null"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc90c3fd-5cec-47d2-e7b4-5f74a68de68a",
        "id": "RgjbY0HGwpUe"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Public URL: NgrokTunnel: \"https://55df-34-23-5-72.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YnNezua62DXN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}